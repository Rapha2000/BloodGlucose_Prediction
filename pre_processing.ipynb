{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting XML files into CSV files"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataset has been provided to us in XML format, we will first write a function to convert these XML files into CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.options.display.float_format = '{:.2f}'.format "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xml_to_csv(train_bool, test_bool, year, patient_nb, variable):\n",
    "    # Open the patient's XML train or XML test file and parse it with ElementTree\n",
    "    if train_bool:\n",
    "        tree = ET.parse(f\"data/xml/{year}/train/{patient_nb}-ws-training.xml\")\n",
    "    elif test_bool:\n",
    "        tree = ET.parse(f\"data/xml/{year}/test/{patient_nb}-ws-testing.xml\")\n",
    "    else:\n",
    "        raise ValueError(\"You must specify either train_bool or test_bool as True.\")\n",
    "    \n",
    "    root = tree.getroot()\n",
    "\n",
    "    # Open the CSV file in write mode and create a csv.writer object\n",
    "    if train_bool:\n",
    "        csv_filename = f\"data/csv/{year}/train/{patient_nb}-ws-training-{variable}.csv\"\n",
    "    elif test_bool:\n",
    "        csv_filename = f\"data/csv/{year}/test/{patient_nb}-ws-testing-{variable}.csv\"\n",
    "    with open(csv_filename, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "\n",
    "        if variable == \"glucose_level\":\n",
    "            # Write the column headers in the CSV file\n",
    "            writer.writerow(['ts', 'value'])\n",
    "\n",
    "            # Browse the elements of the XML file and write the data to the CSV file\n",
    "            for child in root[0]:\n",
    "                row = []\n",
    "                row.append(child.attrib['ts'])\n",
    "                row.append(child.attrib['value'])\n",
    "                writer.writerow(row)\n",
    "\n",
    "        elif variable == \"basis_heart_rate\":\n",
    "            # Write the column headers in the CSV file\n",
    "            writer.writerow(['ts', 'value'])\n",
    "\n",
    "            # Browse the elements of the XML file and write the data to the CSV file\n",
    "            for child in root[12]:\n",
    "                row = []\n",
    "                row.append(child.attrib['ts'])\n",
    "                row.append(child.attrib['value'])\n",
    "                writer.writerow(row)\n",
    "\n",
    "        elif variable == \"basal\":\n",
    "            # Write the column headers in the CSV file\n",
    "            writer.writerow(['ts', 'value'])\n",
    "\n",
    "            # Browse the elements of the XML file and write the data to the CSV file\n",
    "            for child in root[2]:\n",
    "                row = []\n",
    "                row.append(child.attrib['ts'])\n",
    "                row.append(child.attrib['value'])\n",
    "                writer.writerow(row)\n",
    "\n",
    "        elif variable == \"bolus\":\n",
    "            # Write the column headers in the CSV file\n",
    "            writer.writerow(['ts_begin', 'ts_end', 'type', 'dose', 'bwz_carb_input'])\n",
    "\n",
    "            # Browse the elements of the XML file and write the data to the CSV file\n",
    "            for child in root[4]:\n",
    "                row = []\n",
    "                row.append(child.attrib['ts_begin'])\n",
    "                row.append(child.attrib['ts_end'])\n",
    "                row.append(child.attrib['type'])\n",
    "                row.append(child.attrib['dose'])\n",
    "                row.append(child.attrib['bwz_carb_input'])\n",
    "                writer.writerow(row)\n",
    "\n",
    "        elif variable == \"exercise\":\n",
    "            # Write the column headers in the CSV file\n",
    "            writer.writerow(['ts', 'intensity', 'type', 'duration', 'competitive'])\n",
    "\n",
    "            # Browse the elements of the XML file and write the data to the CSV file\n",
    "            for child in root[11]:\n",
    "                row = []\n",
    "                row.append(child.attrib['ts'])\n",
    "                row.append(child.attrib['intensity'])\n",
    "                row.append(child.attrib['type'])\n",
    "                row.append(child.attrib['duration'])\n",
    "                row.append(child.attrib['competitive'])\n",
    "                writer.writerow(row)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"You must specify either a variable.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the Multivariate Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the different patients in the study, we had access to many variables (see dataset description: http://smarthealth.cs.ohio.edu/OhioT1DM-dataset.html). We made the arbitrary choice to keep only some variables for our model (glucose leve, basal, bolus, exercise, basis heart rate). We create here a function that takes care of pre-processing the data and creating the multivariate dataset that will allow us to implement our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/xml/2018/train/559-ws-training.xml'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# we create all the csv files that will be useful\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m xml_to_csv(\u001b[39mTrue\u001b[39;49;00m, \u001b[39mFalse\u001b[39;49;00m, \u001b[39m\"\u001b[39;49m\u001b[39m2018\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39m559\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mglucose_level\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      3\u001b[0m xml_to_csv(\u001b[39mFalse\u001b[39;00m, \u001b[39mTrue\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39m2018\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m559\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mglucose_level\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m xml_to_csv(\u001b[39mTrue\u001b[39;00m, \u001b[39mFalse\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39m2018\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m559\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mbasis_heart_rate\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[2], line 4\u001b[0m, in \u001b[0;36mxml_to_csv\u001b[1;34m(train_bool, test_bool, year, patient_nb, variable)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mxml_to_csv\u001b[39m(train_bool, test_bool, year, patient_nb, variable):\n\u001b[0;32m      2\u001b[0m     \u001b[39m# Open the patient's XML train or XML test file and parse it with ElementTree\u001b[39;00m\n\u001b[0;32m      3\u001b[0m     \u001b[39mif\u001b[39;00m train_bool:\n\u001b[1;32m----> 4\u001b[0m         tree \u001b[39m=\u001b[39m ET\u001b[39m.\u001b[39;49mparse(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mdata/xml/\u001b[39;49m\u001b[39m{\u001b[39;49;00myear\u001b[39m}\u001b[39;49;00m\u001b[39m/train/\u001b[39;49m\u001b[39m{\u001b[39;49;00mpatient_nb\u001b[39m}\u001b[39;49;00m\u001b[39m-ws-training.xml\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      5\u001b[0m     \u001b[39melif\u001b[39;00m test_bool:\n\u001b[0;32m      6\u001b[0m         tree \u001b[39m=\u001b[39m ET\u001b[39m.\u001b[39mparse(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdata/xml/\u001b[39m\u001b[39m{\u001b[39;00myear\u001b[39m}\u001b[39;00m\u001b[39m/test/\u001b[39m\u001b[39m{\u001b[39;00mpatient_nb\u001b[39m}\u001b[39;00m\u001b[39m-ws-testing.xml\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\rapha\\miniconda3\\envs\\diabete\\lib\\xml\\etree\\ElementTree.py:1222\u001b[0m, in \u001b[0;36mparse\u001b[1;34m(source, parser)\u001b[0m\n\u001b[0;32m   1213\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Parse XML document into element tree.\u001b[39;00m\n\u001b[0;32m   1214\u001b[0m \n\u001b[0;32m   1215\u001b[0m \u001b[39m*source* is a filename or file object containing XML data,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1219\u001b[0m \n\u001b[0;32m   1220\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1221\u001b[0m tree \u001b[39m=\u001b[39m ElementTree()\n\u001b[1;32m-> 1222\u001b[0m tree\u001b[39m.\u001b[39;49mparse(source, parser)\n\u001b[0;32m   1223\u001b[0m \u001b[39mreturn\u001b[39;00m tree\n",
      "File \u001b[1;32mc:\\Users\\rapha\\miniconda3\\envs\\diabete\\lib\\xml\\etree\\ElementTree.py:569\u001b[0m, in \u001b[0;36mElementTree.parse\u001b[1;34m(self, source, parser)\u001b[0m\n\u001b[0;32m    567\u001b[0m close_source \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    568\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(source, \u001b[39m\"\u001b[39m\u001b[39mread\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m--> 569\u001b[0m     source \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(source, \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m    570\u001b[0m     close_source \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    571\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/xml/2018/train/559-ws-training.xml'"
     ]
    }
   ],
   "source": [
    "# we create all the csv files that will be useful\n",
    "xml_to_csv(True, False, \"2018\", \"559\", \"glucose_level\")\n",
    "xml_to_csv(False, True, \"2018\", \"559\", \"glucose_level\")\n",
    "\n",
    "xml_to_csv(True, False, \"2018\", \"559\", \"basis_heart_rate\")\n",
    "xml_to_csv(False, True, \"2018\", \"559\", \"basis_heart_rate\")\n",
    "\n",
    "xml_to_csv(True, False, \"2018\", \"559\", \"basal\")\n",
    "xml_to_csv(False, True, \"2018\", \"559\", \"basal\")\n",
    "\n",
    "xml_to_csv(True, False, \"2018\", \"559\", \"bolus\")\n",
    "xml_to_csv(False, True, \"2018\", \"559\", \"bolus\")\n",
    "\n",
    "xml_to_csv(True, False, \"2018\", \"559\", \"exercise\")\n",
    "xml_to_csv(False, True, \"2018\", \"559\", \"exercise\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we import our dataframes\n",
    "bg_train_df = pd.read_csv('data/csv/2018/train/559-ws-training-glucose_level.csv')\n",
    "bg_test_df = pd.read_csv('data/csv/2018/test/559-ws-testing-glucose_level.csv')\n",
    "\n",
    "bhr_train_df = pd.read_csv('data/csv/2018/train/559-ws-training-basis_heart_rate.csv')\n",
    "bhr_test_df = pd.read_csv('data/csv/2018/test/559-ws-testing-basis_heart_rate.csv')\n",
    "\n",
    "bol_train_df = pd.read_csv('data/csv/2018/train/559-ws-training-bolus.csv')\n",
    "bol_test_df = pd.read_csv('data/csv/2018/test/559-ws-testing-bolus.csv')\n",
    "\n",
    "bas_train_df = pd.read_csv('data/csv/2018/train/559-ws-training-basal.csv')\n",
    "bas_test_df = pd.read_csv('data/csv/2018/test/559-ws-testing-basal.csv')\n",
    "\n",
    "exo_train_df = pd.read_csv('data/csv/2018/train/559-ws-training-exercise.csv')\n",
    "exo_test_df = pd.read_csv('data/csv/2018/test/559-ws-testing-exercise.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_multivariate_datasets(bg_train_df, bg_test_df,\n",
    "                                bhr_train_df, bhr_test_df,\n",
    "                                bas_train_df, bas_test_df,\n",
    "                                bol_train_df, bol_test_df,\n",
    "                                exo_train_df, exo_test_df):\n",
    "    \n",
    "    # on convertit toutes les colonnes 'timestamp' en colonnes de type datetime\n",
    "    bg_train_df['ts'] = pd.to_datetime(bg_train_df['ts'], format = \"%d-%m-%Y %H:%M:%S\")\n",
    "    bg_test_df['ts'] = pd.to_datetime(bg_test_df['ts'], format = \"%d-%m-%Y %H:%M:%S\")\n",
    "\n",
    "    bhr_train_df['ts'] = pd.to_datetime(bhr_train_df['ts'], format = \"%d-%m-%Y %H:%M:%S\")\n",
    "    bhr_test_df['ts'] = pd.to_datetime(bhr_test_df['ts'], format = \"%d-%m-%Y %H:%M:%S\")\n",
    "\n",
    "    bol_train_df['ts_begin'] = pd.to_datetime(bol_train_df['ts_begin'], format = \"%d-%m-%Y %H:%M:%S\")\n",
    "    bol_train_df['ts_end'] = pd.to_datetime(bol_train_df['ts_end'], format = \"%d-%m-%Y %H:%M:%S\")\n",
    "    bol_test_df['ts_begin'] = pd.to_datetime(bol_test_df['ts_begin'], format = \"%d-%m-%Y %H:%M:%S\")\n",
    "    bol_test_df['ts_end'] = pd.to_datetime(bol_test_df['ts_end'], format = \"%d-%m-%Y %H:%M:%S\")\n",
    "\n",
    "    bas_train_df['ts'] = pd.to_datetime(bas_train_df['ts'], format = \"%d-%m-%Y %H:%M:%S\")\n",
    "    bas_test_df['ts'] = pd.to_datetime(bas_test_df['ts'], format = \"%d-%m-%Y %H:%M:%S\")\n",
    "\n",
    "    exo_train_df['ts'] = pd.to_datetime(exo_train_df['ts'], format = \"%d-%m-%Y %H:%M:%S\")\n",
    "    exo_test_df['ts'] = pd.to_datetime(exo_test_df['ts'], format = \"%d-%m-%Y %H:%M:%S\")\n",
    "\n",
    "\n",
    "\n",
    "    # on supprime les colonnes inutiles\n",
    "    bol_train_df = bol_train_df.drop('ts_end', axis=1) # car ts_end identique à ts_begin\n",
    "    bol_test_df = bol_test_df.drop('ts_end', axis=1)\n",
    "    bol_train_df = bol_train_df.drop('type', axis=1) # car 'type' ne change pas de valeur\n",
    "    bol_test_df = bol_test_df.drop('type', axis=1)\n",
    "\n",
    "    exo_train_df = exo_train_df.drop('type', axis=1) # car 'type' vide\n",
    "    exo_test_df = exo_test_df.drop('type', axis=1)\n",
    "    exo_train_df = exo_train_df.drop('competitive', axis=1) # car NA\n",
    "    exo_test_df = exo_test_df.drop('competitive', axis=1)\n",
    "\n",
    "    ### regrouper les dataframes bg et bhr\n",
    "\n",
    "    ## faire correspondre les dates de débuts et de fin des dataframes\n",
    "\n",
    "    # train\n",
    "    # date début bg_train_df = 2021-12-07 01:17:00\n",
    "    # date début bhr_train_df = 2021-12-07 12:57:00\n",
    "    bg_train_df = bg_train_df[bg_train_df['ts'] > '2021-12-07 12:52:00']\n",
    "\n",
    "    # date fin bg_train_df = 2022-01-17 23:56:00\n",
    "    # date fin bhr_train_df = 2022-01-17 23:55:00\n",
    "\n",
    "    # test\n",
    "    # date début bg_test_df = 2022-01-18 00:01:00\t\n",
    "    # date début bhr_test_df = 2022-01-18 00:00:00\n",
    "\n",
    "    # date fin bg_test_df = 2022-01-27 23:38:00\n",
    "    # date fin bhr_test_df = 2022-01-27 17:55:00\n",
    "    bg_test_df = bg_test_df[bg_test_df['ts'] < '2022-01-27 17:55:00']\n",
    "\n",
    "    ## fusion des deux datasets\n",
    "\n",
    "    # train\n",
    "    bg_train_df = bg_train_df.set_index('ts')\n",
    "    bhr_train_df = bhr_train_df.set_index('ts')\n",
    "\n",
    "    bg_train_df = bg_train_df.rename(columns = {'value': 'value_bg'})\n",
    "    bhr_train_df = bhr_train_df.rename(columns = {'value': 'value_bhr'})\n",
    "\n",
    "    merged_train_df = bg_train_df.join(bhr_train_df, how='outer')\n",
    "\n",
    "    # test\n",
    "    bg_test_df = bg_test_df.set_index('ts')\n",
    "    bhr_test_df = bhr_test_df.set_index('ts')\n",
    "\n",
    "    bg_test_df = bg_test_df.rename(columns = {'value': 'value_bg'})\n",
    "    bhr_test_df = bhr_test_df.rename(columns = {'value': 'value_bhr'})\n",
    "\n",
    "    merged_test_df = bg_test_df.join(bhr_test_df, how='outer')\n",
    "\n",
    "    ## imputation des valeurs manquantes\n",
    "\n",
    "    # train\n",
    "    merged_train_df['value_bg'] = merged_train_df['value_bg'].interpolate(method='time')\n",
    "    merged_train_df['value_bhr'] = merged_train_df['value_bhr'].interpolate(method='time')\n",
    "\n",
    "    # test\n",
    "    merged_test_df.loc['2022-01-18 00:00:00', 'value_bg'] = 179\n",
    "\n",
    "    merged_test_df['value_bg'] = merged_test_df['value_bg'].interpolate(method='time')\n",
    "    merged_test_df['value_bhr'] = merged_test_df['value_bhr'].interpolate(method='time')\n",
    "\n",
    "\n",
    "\n",
    "    ### regrouper les dataframes bg, bhr et bas\n",
    "\n",
    "    ## faire correspondre les dates de débuts et de fin des dataframes\n",
    "    bas_train_df = bas_train_df[bas_train_df['ts'] > '2021-12-08 00:00:00'] # la date de début doit être postérieure à la date de début du df merged_train_df\n",
    "\n",
    "    ## fusion des deux datasets\n",
    "    bas_train_df = bas_train_df.set_index('ts')\n",
    "    bas_train_df = bas_train_df.rename(columns = {'value': 'value_bas'})\n",
    "\n",
    "    bas_test_df = bas_test_df.set_index('ts')\n",
    "    bas_test_df = bas_test_df.rename(columns = {'value': 'value_bas'})\n",
    "\n",
    "    merged_train_df = merged_train_df.join(bas_train_df, how='outer')\n",
    "    merged_test_df = merged_test_df.join(bas_test_df, how='outer')\n",
    "\n",
    "    ## imputation des valeurs manquantes\n",
    "    merged_train_df['value_bg'] = merged_train_df['value_bg'].interpolate(method='time')\n",
    "    merged_train_df['value_bhr'] = merged_train_df['value_bhr'].interpolate(method='time')\n",
    "\n",
    "    merged_test_df['value_bg'] = merged_test_df['value_bg'].interpolate(method='time')\n",
    "    merged_test_df['value_bhr'] = merged_test_df['value_bhr'].interpolate(method='time')\n",
    "\n",
    "    merged_train_df['value_bas'] = merged_train_df['value_bas'].fillna(0)\n",
    "    merged_test_df['value_bas'] = merged_test_df['value_bas'].fillna(0)\n",
    "\n",
    "\n",
    "\n",
    "    ### regrouper les dataframes bg, bhr, bas et exo\n",
    "    exo_train_df = exo_train_df.set_index('ts')\n",
    "    exo_test_df = exo_test_df.set_index('ts')\n",
    "\n",
    "    exo_train_df = exo_train_df.rename(columns = {'intensity': 'intensity_exo', 'duration': 'duration_exo'})\n",
    "    exo_test_df = exo_test_df.rename(columns = {'intensity': 'intensity_exo', 'duration': 'duration_exo'})\n",
    "\n",
    "\n",
    "    merged_train_df = merged_train_df.join(exo_train_df, how='outer')\n",
    "    merged_test_df = merged_test_df.join(exo_test_df, how='outer')\n",
    "\n",
    "\n",
    "    merged_train_df['value_bg'] = merged_train_df['value_bg'].interpolate(method='time')\n",
    "    merged_train_df['value_bhr'] = merged_train_df['value_bhr'].interpolate(method='time')\n",
    "\n",
    "    merged_test_df['value_bg'] = merged_test_df['value_bg'].interpolate(method='time')\n",
    "    merged_test_df['value_bhr'] = merged_test_df['value_bhr'].interpolate(method='time')\n",
    "\n",
    "\n",
    "    merged_train_df['value_bas'] = merged_train_df['value_bas'].fillna(0)\n",
    "    merged_train_df['intensity_exo'] = merged_train_df['intensity_exo'].fillna(0)\n",
    "    merged_train_df['duration_exo'] = merged_train_df['duration_exo'].fillna(0)\n",
    "\n",
    "    merged_test_df['value_bas'] = merged_test_df['value_bas'].fillna(0)\n",
    "    merged_test_df['intensity_exo'] = merged_test_df['intensity_exo'].fillna(0)\n",
    "    merged_test_df['duration_exo'] = merged_test_df['duration_exo'].fillna(0)\n",
    "\n",
    "\n",
    "\n",
    "    ### regrouper les dataframes bg, bhr, bas, exo et bolus\n",
    "    bol_train_df.rename(columns={\"ts_begin\": \"ts\"}, inplace=True)\n",
    "    bol_test_df.rename(columns={\"ts_begin\": \"ts\"}, inplace=True)\n",
    "\n",
    "    bol_train_df = bol_train_df[bol_train_df['ts'] > '2021-12-07 12:57:00']\n",
    "    bol_test_df = bol_test_df[bol_test_df['ts'] < '2022-01-27 17:55:00']\n",
    "\n",
    "    bol_train_df = bol_train_df.set_index('ts')\n",
    "    bol_test_df = bol_test_df.set_index('ts')\n",
    "\n",
    "\n",
    "    bol_train_df = bol_train_df.rename(columns = {'dose': 'dose_bolus', 'bwz_carb_input': 'bolus_carbs_input'})\n",
    "    bol_test_df = bol_test_df.rename(columns = {'dose': 'dose_bolus', 'bwz_carb_input': 'bolus_carbs_input'})\n",
    "\n",
    "    merged_train_df = merged_train_df.join(bol_train_df, how='outer')\n",
    "    merged_test_df = merged_test_df.join(bol_test_df, how='outer')\n",
    "\n",
    "    merged_train_df['value_bg'] = merged_train_df['value_bg'].interpolate(method='time')\n",
    "    merged_train_df['value_bhr'] = merged_train_df['value_bhr'].interpolate(method='time')\n",
    "\n",
    "    merged_test_df['value_bg'] = merged_test_df['value_bg'].interpolate(method='time')\n",
    "    merged_test_df['value_bhr'] = merged_test_df['value_bhr'].interpolate(method='time')\n",
    "\n",
    "\n",
    "    merged_train_df['value_bas'] = merged_train_df['value_bas'].fillna(0)\n",
    "    merged_train_df['intensity_exo'] = merged_train_df['intensity_exo'].fillna(0)\n",
    "    merged_train_df['duration_exo'] = merged_train_df['duration_exo'].fillna(0)\n",
    "    merged_train_df['dose_bolus'] = merged_train_df['dose_bolus'].fillna(0)\n",
    "    merged_train_df['bolus_carbs_input'] = merged_train_df['bolus_carbs_input'].fillna(0)\n",
    "\n",
    "    merged_test_df['value_bas'] = merged_test_df['value_bas'].fillna(0)\n",
    "    merged_test_df['intensity_exo'] = merged_test_df['intensity_exo'].fillna(0)\n",
    "    merged_test_df['duration_exo'] = merged_test_df['duration_exo'].fillna(0)\n",
    "    merged_test_df['dose_bolus'] = merged_test_df['dose_bolus'].fillna(0)\n",
    "    merged_test_df['bolus_carbs_input'] = merged_test_df['bolus_carbs_input'].fillna(0)\n",
    "\n",
    "    return merged_train_df, merged_test_df        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diabetes_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
